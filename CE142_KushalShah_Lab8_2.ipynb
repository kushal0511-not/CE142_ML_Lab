{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CE175_PrinceVanani_Lab8_Part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kjMxkDkcrGZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\",\n",
        "\"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\",\n",
        "\"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\",\n",
        "\"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\",\n",
        "\"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
        "\"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\",\n",
        "\"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\",\n",
        "\"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\",\n",
        "\"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\",\n",
        "\"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\",\n",
        "\"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\",\n",
        "\"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\",\n",
        "\"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\",\n",
        "\"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\",\n",
        "\"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "\"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\",\n",
        "\"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\",\n",
        "\"yourselves\"]"
      ],
      "metadata": {
        "id": "f9blU4Dsc78P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "datasets = pd.read_csv('/content/spam.csv', encoding=\"ISO-8859-1\")\n",
        "datasets.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1, inplace = True)\n",
        "datasets[\"v1\"]=np.where(datasets[\"v1\"]=='spam',1,0)\n",
        "print(\"\\nData :\\n\",datasets.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U21UDmxwdECh",
        "outputId": "0bbc6eca-d209-420e-c2f2-01b697341658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data :\n",
            "     v1                                                 v2\n",
            "0    0  Go until jurong point, crazy.. Available only ...\n",
            "1    0                      Ok lar... Joking wif u oni...\n",
            "2    1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3    0  U dun say so early hor... U c already then say...\n",
            "4    0  Nah I don't think he goes to usf, he lives aro...\n",
            "5    1  FreeMsg Hey there darling it's been 3 week's n...\n",
            "6    0  Even my brother is not like to speak with me. ...\n",
            "7    0  As per your request 'Melle Melle (Oru Minnamin...\n",
            "8    1  WINNER!! As a valued network customer you have...\n",
            "9    1  Had your mobile 11 months or more? U R entitle...\n",
            "10   0  I'm gonna be home soon and i don't want to tal...\n",
            "11   1  SIX chances to win CASH! From 100 to 20,000 po...\n",
            "12   1  URGENT! You have won a 1 week FREE membership ...\n",
            "13   0  I've been searching for the right words to tha...\n",
            "14   0                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
            "15   1  XXXMobileMovieClub: To use your credit, click ...\n",
            "16   0                         Oh k...i'm watching here:)\n",
            "17   0  Eh u remember how 2 spell his name... Yes i di...\n",
            "18   0  Fine if thatåÕs the way u feel. ThatåÕs the wa...\n",
            "19   1  England v Macedonia - dont miss the goals/team...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(datasets[\"v2\"], datasets[\"v1\"],random_state=175)\n",
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opvvouGrdckg",
        "outputId": "7c609b45-c40c-4730-efbd-3be11e325806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1393,)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer\n",
        "\n",
        "\n",
        "Perform count vectorization on training data."
      ],
      "metadata": {
        "id": "k15Sq8WRydf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(ngram_range = (2, 2),stop_words=stopwords)\n",
        "vectorizer.fit(X_train)\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "# print(vectorizer.get_feature_names())\n",
        "print(X_train_vectorized.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq4bVHK6di2s",
        "outputId": "867dc0a9-7e58-4c09-b089-16a2aca18923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let', 'll', 're', 've'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "model=MultinomialNB()\n",
        "model.fit(X_train_vectorized,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoT69Lv-dl-T",
        "outputId": "41eff553-2151-49ea-e7ae-2bd5d15a4778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "predictions = model.predict(vectorizer.transform(X_test))\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "print(\"\\nPrecision: \", precision_score(y_test, predictions))\n",
        "print(\"\\nRecall: \", recall_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmT4ZJIxy1Tf",
        "outputId": "e8fef912-0cc2-4a38-9839-22fd1a69ac7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9820531227566404\n",
            "\n",
            "Precision:  0.993421052631579\n",
            "\n",
            "Recall:  0.8628571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the Decision Tree Classifier on vectorized data."
      ],
      "metadata": {
        "id": "VTOQVNkTzTNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train_vectorized, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg6Ug6DIzSSY",
        "outputId": "e5e0a6c8-c3f3-4d62-c8b0-8c242622305c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "predictions = clf.predict(vectorizer.transform(X_test))\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "print(\"\\nPrecision: \", precision_score(y_test, predictions))\n",
        "print(\"\\nRecall: \", recall_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxW8lZaCzfpo",
        "outputId": "6dd8ecf6-db97-4e7c-a2ed-95dcdf3e2429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9655419956927495\n",
            "\n",
            "Precision:  0.9774436090225563\n",
            "\n",
            "Recall:  0.7428571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFIDF Vectorizer\n",
        "\n",
        "\n",
        "Perform IFIDF vectorization on training data."
      ],
      "metadata": {
        "id": "ApfVqzCu2OB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range = (2, 2),stop_words = stopwords)\n",
        "vectorizer.fit(X_train)\n",
        "X_train_tfidf_vectorized = vectorizer.transform(X_train)\n",
        "print(X_train_tfidf_vectorized.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgzTG3-l2UCF",
        "outputId": "3d8e275b-aaee-453e-989a-08540ce79f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['let', 'll', 're', 've'] not in stop_words.\n",
            "  % sorted(inconsistent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Apply the Naive Bayes on IFIDF vectorized data."
      ],
      "metadata": {
        "id": "o_lQkG2P3N6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf_vectorized, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE8QckeL3NiT",
        "outputId": "801fc7ee-5054-4cb2-cb9a-83e8643adb38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(vectorizer.transform(X_test))\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "print(\"\\nPrecision: \", precision_score(y_test, predictions))\n",
        "print(\"\\nRecall: \", recall_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98Wki1OV3a7R",
        "outputId": "35fdc8db-5856-49bb-e88d-056842ab0c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9526202440775305\n",
            "\n",
            "Precision:  1.0\n",
            "\n",
            "Recall:  0.6228571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the Decision Tree Classifier on IFIDF vectorized data."
      ],
      "metadata": {
        "id": "6iQUmaIb3pKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train_tfidf_vectorized, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vermn96X3o4-",
        "outputId": "e7e9eb74-91eb-475c-93fc-74dca9904b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = clf.predict(vectorizer.transform(X_test))\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "print(\"\\nPrecision: \", precision_score(y_test, predictions))\n",
        "print(\"\\nRecall: \", recall_score(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmbgnjIK3yvg",
        "outputId": "c7bbdeca-78fc-4c67-8d84-efd0e80cca4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9641062455132807\n",
            "\n",
            "Precision:  0.9770992366412213\n",
            "\n",
            "Recall:  0.7314285714285714\n"
          ]
        }
      ]
    }
  ]
}